{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41272c33",
   "metadata": {},
   "source": [
    "# SDSS Performance Comparison | Hollis McLeod, Elijah Johnson\n",
    "\n",
    "The following code is the product of the combined efforts of Hollis McLeod and Elijah Johnson for the term project in the Fall 2025 Section #22904 of AST4930 - Special Topics: Machine Learning at the University of Florida. This code is not for viewing, use, analysis, or any other purposes not in compliance with the [University of Florida Honor Code](https://policy.ufl.edu/regulation/4-040/). Violations will be reported accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ee3aa",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4f37c",
   "metadata": {},
   "source": [
    "This Jupyter notebook defines a method for reading, processing, training machine learning models on, and visualizing results for [SDSS data](https://skyserver.sdss.org/dr19/SearchTools/sql) of the following form.\n",
    "\n",
    "500,000 rows were downloaded as *SDSS.csv*, although 100,000 rows are planned for use. If computational power permits, however, more will be used for increased rigor of analysis.\n",
    "\n",
    "**Fields**:\n",
    "- Identification and standard features of astronomical objects (not used for training)\n",
    "  - `objid`\n",
    "  - `ra`\n",
    "  - `dec`\n",
    "  - `specobjid`\n",
    "- Magnitudes\n",
    "  - `u`\n",
    "  - `g`\n",
    "  - `r`\n",
    "  - `i`\n",
    "  - `z`\n",
    "- Color indices (calculated)\n",
    "  - `u-g`\n",
    "  - `g-r`\n",
    "  - `r-i`\n",
    "  - `i-z`\n",
    "- `redshift`\n",
    "- `class`\n",
    "  - \"GALAXY\"\n",
    "  - \"QSO\" (shorthand for quasar)\n",
    "  - \"STAR\"\n",
    "\n",
    "**SQL Code**:\n",
    "```\n",
    "SELECT TOP 500000\n",
    "p.objid,p.ra,p.dec,p.u,p.g,p.r,p.i,p.z,\n",
    "p.u-p.g as 'u-g', p.g-p.r as 'g-r', p.r-p.i as 'r-i', p.i-p.z as 'i-z',\n",
    "s.specobjid, s.class, s.z as redshift\n",
    "FROM PhotoObj AS p\n",
    "JOIN SpecObj AS s ON s.bestobjid = p.objid\n",
    "WHERE s.class IN ('GALAXY', 'QSO', 'STAR')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed0472",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f815e896",
   "metadata": {},
   "source": [
    "### Install and Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "360809dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.32.5)\n",
      "Collecting setuptools (from tensorflow)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.3.2)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.1-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\eli\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "   ---------------------------------------- 0.0/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.7/331.9 MB 24.2 MB/s eta 0:00:14\n",
      "    --------------------------------------- 6.3/331.9 MB 29.7 MB/s eta 0:00:11\n",
      "    --------------------------------------- 6.3/331.9 MB 29.7 MB/s eta 0:00:11\n",
      "    --------------------------------------- 6.6/331.9 MB 8.1 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 9.7/331.9 MB 9.7 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 11.5/331.9 MB 9.6 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 11.5/331.9 MB 9.6 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 11.5/331.9 MB 9.6 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 18.9/331.9 MB 10.3 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 22.8/331.9 MB 11.5 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 29.9/331.9 MB 13.1 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 41.2/331.9 MB 16.6 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 46.1/331.9 MB 17.2 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 59.8/331.9 MB 20.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 62.9/331.9 MB 21.2 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 68.4/331.9 MB 20.7 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 71.8/331.9 MB 20.3 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 75.2/331.9 MB 20.2 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 87.6/331.9 MB 22.2 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 94.4/331.9 MB 23.3 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 94.4/331.9 MB 23.3 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 94.4/331.9 MB 23.3 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 94.6/331.9 MB 19.9 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 94.6/331.9 MB 19.9 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 94.6/331.9 MB 19.9 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 94.6/331.9 MB 19.9 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 94.9/331.9 MB 17.1 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 95.2/331.9 MB 16.5 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 95.2/331.9 MB 16.5 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 95.2/331.9 MB 16.5 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 95.2/331.9 MB 16.5 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 95.2/331.9 MB 16.5 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 97.5/331.9 MB 14.2 MB/s eta 0:00:17\n",
      "   ------------ -------------------------- 107.0/331.9 MB 15.2 MB/s eta 0:00:15\n",
      "   ------------- ------------------------- 113.2/331.9 MB 15.7 MB/s eta 0:00:14\n",
      "   ------------- ------------------------- 114.8/331.9 MB 15.4 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 120.6/331.9 MB 15.7 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 123.7/331.9 MB 15.8 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 124.8/331.9 MB 15.4 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 125.3/331.9 MB 15.1 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 126.1/331.9 MB 14.8 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 127.1/331.9 MB 14.5 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 127.9/331.9 MB 14.6 MB/s eta 0:00:14\n",
      "   --------------- ----------------------- 133.2/331.9 MB 14.5 MB/s eta 0:00:14\n",
      "   --------------- ----------------------- 133.2/331.9 MB 14.5 MB/s eta 0:00:14\n",
      "   --------------- ----------------------- 133.2/331.9 MB 14.5 MB/s eta 0:00:14\n",
      "   --------------- ----------------------- 133.2/331.9 MB 14.5 MB/s eta 0:00:14\n",
      "   --------------- ----------------------- 133.2/331.9 MB 14.5 MB/s eta 0:00:14\n",
      "   --------------- ----------------------- 133.4/331.9 MB 13.3 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 133.7/331.9 MB 12.9 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 133.7/331.9 MB 12.9 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 133.7/331.9 MB 12.9 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 134.0/331.9 MB 12.4 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 134.0/331.9 MB 12.4 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 134.0/331.9 MB 12.4 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 134.2/331.9 MB 11.5 MB/s eta 0:00:18\n",
      "   --------------- ----------------------- 134.5/331.9 MB 11.3 MB/s eta 0:00:18\n",
      "   --------------- ----------------------- 135.3/331.9 MB 11.3 MB/s eta 0:00:18\n",
      "   ---------------- ---------------------- 137.9/331.9 MB 11.2 MB/s eta 0:00:18\n",
      "   ---------------- ---------------------- 144.4/331.9 MB 11.6 MB/s eta 0:00:17\n",
      "   ----------------- --------------------- 151.3/331.9 MB 11.9 MB/s eta 0:00:16\n",
      "   ------------------ -------------------- 156.2/331.9 MB 12.1 MB/s eta 0:00:15\n",
      "   ------------------- ------------------- 164.6/331.9 MB 12.5 MB/s eta 0:00:14\n",
      "   -------------------- ------------------ 170.9/331.9 MB 12.8 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 170.9/331.9 MB 12.8 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 170.9/331.9 MB 12.8 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 173.5/331.9 MB 12.4 MB/s eta 0:00:13\n",
      "   --------------------- ----------------- 183.0/331.9 MB 12.9 MB/s eta 0:00:12\n",
      "   ---------------------- ---------------- 188.7/331.9 MB 13.1 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 199.2/331.9 MB 13.6 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 207.1/331.9 MB 13.9 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 209.5/331.9 MB 13.9 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 209.7/331.9 MB 13.9 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 217.1/331.9 MB 14.1 MB/s eta 0:00:09\n",
      "   ------------------------- ------------- 219.2/331.9 MB 14.1 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 219.7/331.9 MB 13.8 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 223.3/331.9 MB 13.9 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 230.7/331.9 MB 14.2 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 233.6/331.9 MB 14.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ---------- 241.2/331.9 MB 14.4 MB/s eta 0:00:07\n",
      "   ---------------------------- ---------- 244.8/331.9 MB 14.5 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 253.8/331.9 MB 14.9 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 254.5/331.9 MB 14.7 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 262.1/331.9 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 265.3/331.9 MB 14.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 273.7/331.9 MB 16.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 285.5/331.9 MB 16.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 295.7/331.9 MB 16.3 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 299.1/331.9 MB 16.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 299.6/331.9 MB 16.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 304.1/331.9 MB 15.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 308.5/331.9 MB 15.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 311.2/331.9 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 317.7/331.9 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  324.5/331.9 MB 15.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  327.2/331.9 MB 15.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 331.9/331.9 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 62.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 62.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 10.1 MB/s eta 0:00:00\n",
      "Downloading h5py-3.15.1-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 41.5 MB/s eta 0:00:00\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 37.9 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 13.1/26.4 MB 63.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.4/26.4 MB 42.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.2/26.4 MB 46.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.2/26.4 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 28.4 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 28.0 MB/s eta 0:00:00\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-win_amd64.whl (60 kB)\n",
      "Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-win_amd64.whl (314 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, setuptools, protobuf, optree, opt_einsum, ml_dtypes, mdurl, markdown, h5py, grpcio, google_pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.12.0 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.33.1 rich-14.2.0 setuptools-80.9.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Eli\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install if not already installed.\n",
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install scipy\n",
    "# %pip install matplotlib\n",
    "# %pip install scikit-learn\n",
    "# %pip install seaborn\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b91dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Consolidate all imports together for easy use.\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# For capturing subprocess output with GridSearchCV parallelization\n",
    "from joblib import parallel_backend # TODO: currently unused!\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828cf7d5",
   "metadata": {},
   "source": [
    "### Define Paths and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5c4be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These paths are stored in a dictionary for easy access and non-verbosity\n",
    "paths = {\n",
    "    # location of SDSS data\n",
    "    'data': './data/SDSS.csv',\n",
    "\n",
    "    # base directories for saved graphs, charts, models\n",
    "    'supervised_products': './products/supervised/',\n",
    "    'unsupervised_products': './products/unsupervised/',\n",
    "\n",
    "    # additional pathing for specific products\n",
    "    'graphs': 'graphs/',\n",
    "    'charts': 'charts/',\n",
    "    'models': 'models/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787143ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The number of rows to be used with the data\n",
    "NROWS = 100000\n",
    "\n",
    "# The column names of the features and the class from the dataset\n",
    "FEATURES = ['u', 'g', 'r', 'i', 'z', 'u-g', 'g-r', 'r-i', 'i-z', 'redshift']\n",
    "CLASS = 'class'\n",
    "\n",
    "# The number of CPU cores we want to use for training, when possible. -1 means all that are available.\n",
    "N_JOBS = -1\n",
    "\n",
    "# Lists containing the names of the models in use.\n",
    "SUPERVISED_MODELS = ['kNN', 'DT', 'SVM-C', 'RF-C', 'AdaBoost']\n",
    "UNSUPERVISED_MODELS = ['k-means', 'GMM', 'DBSCAN', 'NN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d7482",
   "metadata": {},
   "source": [
    "### Import Data and Perform Preliminary Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02967757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objid</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>u-g</th>\n",
       "      <th>g-r</th>\n",
       "      <th>r-i</th>\n",
       "      <th>i-z</th>\n",
       "      <th>specobjid</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1237668705156530825</td>\n",
       "      <td>263.370025</td>\n",
       "      <td>7.223793</td>\n",
       "      <td>18.08503</td>\n",
       "      <td>16.13823</td>\n",
       "      <td>15.28424</td>\n",
       "      <td>14.93009</td>\n",
       "      <td>14.71180</td>\n",
       "      <td>1.946796</td>\n",
       "      <td>0.853986</td>\n",
       "      <td>0.354156</td>\n",
       "      <td>0.218284</td>\n",
       "      <td>3149144865661544448</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1237668705693467044</td>\n",
       "      <td>263.664289</td>\n",
       "      <td>7.488496</td>\n",
       "      <td>20.73099</td>\n",
       "      <td>19.08960</td>\n",
       "      <td>18.26207</td>\n",
       "      <td>17.86547</td>\n",
       "      <td>17.68044</td>\n",
       "      <td>1.641390</td>\n",
       "      <td>0.827530</td>\n",
       "      <td>0.396591</td>\n",
       "      <td>0.185038</td>\n",
       "      <td>3172787664193611776</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.735104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1237668705693468328</td>\n",
       "      <td>263.711809</td>\n",
       "      <td>7.529318</td>\n",
       "      <td>19.98693</td>\n",
       "      <td>18.40730</td>\n",
       "      <td>17.72147</td>\n",
       "      <td>17.44062</td>\n",
       "      <td>17.31446</td>\n",
       "      <td>1.579628</td>\n",
       "      <td>0.685833</td>\n",
       "      <td>0.280849</td>\n",
       "      <td>0.126162</td>\n",
       "      <td>3149149538585962496</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1237668571475018376</td>\n",
       "      <td>262.378986</td>\n",
       "      <td>6.996502</td>\n",
       "      <td>25.06067</td>\n",
       "      <td>19.90350</td>\n",
       "      <td>18.44531</td>\n",
       "      <td>17.69727</td>\n",
       "      <td>17.27005</td>\n",
       "      <td>5.157169</td>\n",
       "      <td>1.458197</td>\n",
       "      <td>0.748039</td>\n",
       "      <td>0.427219</td>\n",
       "      <td>3172843739286628352</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1237671696061236496</td>\n",
       "      <td>263.684828</td>\n",
       "      <td>8.193936</td>\n",
       "      <td>20.79169</td>\n",
       "      <td>19.28190</td>\n",
       "      <td>18.61582</td>\n",
       "      <td>18.31616</td>\n",
       "      <td>18.15825</td>\n",
       "      <td>1.509792</td>\n",
       "      <td>0.666075</td>\n",
       "      <td>0.299660</td>\n",
       "      <td>0.157909</td>\n",
       "      <td>3172804431745935360</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1237666209239269489</td>\n",
       "      <td>255.838908</td>\n",
       "      <td>27.333566</td>\n",
       "      <td>18.55913</td>\n",
       "      <td>16.88940</td>\n",
       "      <td>16.21973</td>\n",
       "      <td>15.95857</td>\n",
       "      <td>15.83906</td>\n",
       "      <td>1.669731</td>\n",
       "      <td>0.669672</td>\n",
       "      <td>0.261165</td>\n",
       "      <td>0.119510</td>\n",
       "      <td>3161585838186326016</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1237662638523220956</td>\n",
       "      <td>240.927307</td>\n",
       "      <td>9.760700</td>\n",
       "      <td>23.87011</td>\n",
       "      <td>21.08361</td>\n",
       "      <td>20.28882</td>\n",
       "      <td>20.15691</td>\n",
       "      <td>20.16212</td>\n",
       "      <td>2.786507</td>\n",
       "      <td>0.794788</td>\n",
       "      <td>0.131912</td>\n",
       "      <td>-0.005213</td>\n",
       "      <td>5493271238775429120</td>\n",
       "      <td>QSO</td>\n",
       "      <td>3.426004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1237651737930499236</td>\n",
       "      <td>239.576144</td>\n",
       "      <td>2.691617</td>\n",
       "      <td>23.77327</td>\n",
       "      <td>23.11989</td>\n",
       "      <td>21.43978</td>\n",
       "      <td>20.39449</td>\n",
       "      <td>19.64420</td>\n",
       "      <td>0.653383</td>\n",
       "      <td>1.680111</td>\n",
       "      <td>1.045284</td>\n",
       "      <td>0.750292</td>\n",
       "      <td>5411089616244856832</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.633541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1237662303525143296</td>\n",
       "      <td>254.194683</td>\n",
       "      <td>26.466377</td>\n",
       "      <td>24.63793</td>\n",
       "      <td>21.74906</td>\n",
       "      <td>19.97466</td>\n",
       "      <td>18.97339</td>\n",
       "      <td>18.56893</td>\n",
       "      <td>2.888876</td>\n",
       "      <td>1.774393</td>\n",
       "      <td>1.001272</td>\n",
       "      <td>0.404459</td>\n",
       "      <td>4706452196270823424</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.496634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1237665429183922720</td>\n",
       "      <td>244.101843</td>\n",
       "      <td>16.761803</td>\n",
       "      <td>19.51226</td>\n",
       "      <td>18.28559</td>\n",
       "      <td>17.73398</td>\n",
       "      <td>17.37767</td>\n",
       "      <td>17.17063</td>\n",
       "      <td>1.226671</td>\n",
       "      <td>0.551601</td>\n",
       "      <td>0.356316</td>\n",
       "      <td>0.207035</td>\n",
       "      <td>2478253919650736128</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.091117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     objid          ra        dec         u         g  \\\n",
       "0      1237668705156530825  263.370025   7.223793  18.08503  16.13823   \n",
       "1      1237668705693467044  263.664289   7.488496  20.73099  19.08960   \n",
       "2      1237668705693468328  263.711809   7.529318  19.98693  18.40730   \n",
       "3      1237668571475018376  262.378986   6.996502  25.06067  19.90350   \n",
       "4      1237671696061236496  263.684828   8.193936  20.79169  19.28190   \n",
       "...                    ...         ...        ...       ...       ...   \n",
       "99995  1237666209239269489  255.838908  27.333566  18.55913  16.88940   \n",
       "99996  1237662638523220956  240.927307   9.760700  23.87011  21.08361   \n",
       "99997  1237651737930499236  239.576144   2.691617  23.77327  23.11989   \n",
       "99998  1237662303525143296  254.194683  26.466377  24.63793  21.74906   \n",
       "99999  1237665429183922720  244.101843  16.761803  19.51226  18.28559   \n",
       "\n",
       "              r         i         z       u-g       g-r       r-i       i-z  \\\n",
       "0      15.28424  14.93009  14.71180  1.946796  0.853986  0.354156  0.218284   \n",
       "1      18.26207  17.86547  17.68044  1.641390  0.827530  0.396591  0.185038   \n",
       "2      17.72147  17.44062  17.31446  1.579628  0.685833  0.280849  0.126162   \n",
       "3      18.44531  17.69727  17.27005  5.157169  1.458197  0.748039  0.427219   \n",
       "4      18.61582  18.31616  18.15825  1.509792  0.666075  0.299660  0.157909   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99995  16.21973  15.95857  15.83906  1.669731  0.669672  0.261165  0.119510   \n",
       "99996  20.28882  20.15691  20.16212  2.786507  0.794788  0.131912 -0.005213   \n",
       "99997  21.43978  20.39449  19.64420  0.653383  1.680111  1.045284  0.750292   \n",
       "99998  19.97466  18.97339  18.56893  2.888876  1.774393  1.001272  0.404459   \n",
       "99999  17.73398  17.37767  17.17063  1.226671  0.551601  0.356316  0.207035   \n",
       "\n",
       "                 specobjid   class  redshift  \n",
       "0      3149144865661544448    STAR -0.000976  \n",
       "1      3172787664193611776  GALAXY  0.735104  \n",
       "2      3149149538585962496    STAR -0.000280  \n",
       "3      3172843739286628352    STAR -0.000059  \n",
       "4      3172804431745935360    STAR -0.000074  \n",
       "...                    ...     ...       ...  \n",
       "99995  3161585838186326016    STAR -0.000256  \n",
       "99996  5493271238775429120     QSO  3.426004  \n",
       "99997  5411089616244856832  GALAXY  0.633541  \n",
       "99998  4706452196270823424  GALAXY  0.496634  \n",
       "99999  2478253919650736128  GALAXY  0.091117  \n",
       "\n",
       "[100000 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(paths['data'], nrows=NROWS)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801d69e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPES:\n",
      "  -(100000, 10)\n",
      "  -(100000,)\n",
      "CLASSES: ['GALAXY' 'QSO' 'STAR']\n"
     ]
    }
   ],
   "source": [
    "# Separate into X and Y\n",
    "X = data[FEATURES].values\n",
    "Y = data[CLASS]\n",
    "\n",
    "CLASSES = np.unique(Y)\n",
    "\n",
    "print(f'SHAPES:\\n  -{X.shape}\\n  -{Y.shape}')\n",
    "print(f'CLASSES: {CLASSES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0475d821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef636e18",
   "metadata": {},
   "source": [
    "### Define Methods for Saving and Loading Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a1e51e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine the location for where a specific model is stored.\n",
    "def getloc_for_pkl(model_name):\n",
    "    loc = paths['supervised_products'] if model_name in SUPERVISED_MODELS \\\n",
    "                else paths['unsupervised_products'] if model_name in UNSUPERVISED_MODELS \\\n",
    "                else False\n",
    "    if not loc: raise ValueError('The \\'model_name\\' parameter must be equal to one of the models in use. Please see SUPERVISED_MODELS and UNSUPERVISED_MODELS.')\n",
    "    loc += paths['models']\n",
    "    return loc\n",
    "\n",
    "# Save the model to a specific location with its features in its name.\n",
    "def save_model(model, model_name, feature_str):\n",
    "    loc = getloc_for_pkl(model_name)\n",
    "    with open(f'{loc}{feature_str}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "# Get the feature string of a filename.\n",
    "def get_feature_str_from_filename(f):\n",
    "    title = f.title()\n",
    "    last_backslash_index = title.rfind('\\\\')\n",
    "    filename = title[last_backslash_index + 1:]\n",
    "    last_period_index = filename.rfind('.')\n",
    "    feature_str = filename[:last_period_index]\n",
    "    return feature_str\n",
    "\n",
    "# Get a model from a specific location or by name. If by name, return the first result.\n",
    "def load_model(pkl_name=None, model_name=None, return_feature_str=False):\n",
    "    if model_name: loc = getloc_for_pkl(model_name)\n",
    "\n",
    "    # Get the name of the .pkl file based on which parameter was provided.\n",
    "    filename = glob.glob(f'{loc}{model_name}*.pkl' if model_name else pkl_name)[0]\n",
    "\n",
    "    with open(filename, 'rb') as f: \n",
    "        return pickle.load(f) if not return_feature_str else pickle.load(f), get_feature_str_from_filename(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e06160",
   "metadata": {},
   "source": [
    "## Supervised Machine Learning\n",
    "\n",
    "This section contains training, optimization, testing, and creation of products for the following supervised machine learning algorithms:\n",
    "\n",
    "- k-Nearest Neighbors (kNN)\n",
    "- Decision Tree (DT)\n",
    "- Support Vector Machine Classifier (SVM-C)\n",
    "- Random Forest Classifier (RF-C)\n",
    "- Adaptive Boosting (AdaBoost) with Base DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac6aa8",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b8071",
   "metadata": {},
   "source": [
    "Define parameter grids for each model for `cv=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da15d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CV = 5\n",
    "SCALER = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768626a2",
   "metadata": {},
   "source": [
    "Define functions to create `Pipeline`s for each model, for experimentation and cleanliness. The default values for the hyperparameters may be tweaked and changed, since it is not necessary to risk overcompensating and wasting time for being unsure about what is needed. There will be sufficient evidence provided that the results of these parameters are indeed useful and meaningful, but the code required to determine sufficient ranges of hyperparameters and their respective outputs may not be included in the submission of this notebook.\n",
    "\n",
    "Models requiring feature scaling include a scaler in their pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa5bd6e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for kNN\n",
    "def create_knn_for_grid_search(n_neighbors=np.arange(10)+1, algos=['auto']):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', SCALER), # kNN requires feature scaling!\n",
    "        ('kNN', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'kNN__n_neighbors': n_neighbors,\n",
    "        'kNN__algorithm': algos\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbd598eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for DT\n",
    "def create_dt_for_grid_search(max_depth=np.arange(10)+1, criterion=['gini', 'entropy']):\n",
    "    pipe = Pipeline([\n",
    "        ('DT', DecisionTreeClassifier(random_state=0))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'DT__max_depth': max_depth,\n",
    "        'DT__criterion': criterion\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5592b428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for SVM-C\n",
    "def create_svmc_for_grid_search(C=np.logspace(3, 6, num=4), gamma=np.logspace(-5, 0, num=4)):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', SCALER), # SVM requires feature scaling!\n",
    "        ('SVM-C', SVC(kernel='rbf', random_state=0))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'SVM-C__C': C,\n",
    "        'SVM-C__gamma': gamma\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32548e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for RF-C\n",
    "def create_rfc_for_grid_search(n_estimators=[100, 500, 1000, 5000]):\n",
    "    pipe = Pipeline([\n",
    "        ('RF-C', RandomForestClassifier(oob_score=True, random_state=0))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'RF-C__n_estimators': n_estimators\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a23347f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for AdaBoost with Base DT.\n",
    "def create_adaboost_for_grid_search(n_estimators=[10, 50, 100, 200], learning_rate=[0.001, 0.01, 0.1, 1.0], max_depth=1, criterion='gini'):\n",
    "    # Per Worksheet 5, we want a poor base estimator for AdaBoost, so we default to max_depth=1 and criterion='gini.\n",
    "    pipe = Pipeline([\n",
    "        ('ADA', AdaBoostClassifier(\n",
    "            random_state=0,\n",
    "            estimator=DecisionTreeClassifier(\n",
    "                max_depth=max_depth,\n",
    "                criterion=criterion)))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'ADA__n_estimators': n_estimators,\n",
    "        'ADA__learning_rate': learning_rate\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffc0a3",
   "metadata": {},
   "source": [
    "Define a function to train models using a grid search with `CV` folds and `N_JOBS` cpu cores (defined above). This model takes the outputs of the functions above that produce pipelines and parameter grids for each type of supervised algorithm. This way, creating and training a model can be accomplished in just two lines! Given the volume of training and trial and error that will (likely) be needed, streamlining this process is essential for reducing headache. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89bd6ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to extract the parameters of a model into a meaningful string for titles and filenames.\n",
    "def get_model_and_model_str(gs, model_name=None):\n",
    "    feature_str = ''\n",
    "    model = None\n",
    "    match model_name:\n",
    "        case 'kNN':\n",
    "            model = gs.best_estimator_[1]\n",
    "            n_neighbors = gs.best_params_['kNN__n_neighbors']\n",
    "            algo = gs.best_params_['kNN__algorithm']\n",
    "            feature_str = f'(k={n_neighbors})(algorithm={algo})'\n",
    "        case 'DT':\n",
    "            model = gs.best_estimator_[0]\n",
    "            m_d = gs.best_params_['DT__max_depth']\n",
    "            crit = gs.best_params_['DT__criterion']\n",
    "            feature_str = f'(max_depth={m_d})(criterion={crit})'\n",
    "        case 'SVM-C':\n",
    "            model = gs.best_estimator_[1]\n",
    "            c = gs.best_params_['SVM__C']\n",
    "            gamma = gs.best_params_['SVM__gamma']\n",
    "            feature_str = f'(C={c})(gamma={gamma})'\n",
    "        case 'RF-C':\n",
    "            model = gs.best_estimator_[0]\n",
    "            n_est = gs.best_params_['RF-C__n_estimators']\n",
    "            feature_str = f'(n_estimators={n_est})'\n",
    "        case 'AdaBoost':\n",
    "            model = gs.best_estimator_[0]\n",
    "            n_est = gs.best_params_['ADA__n_estimators']\n",
    "            learn_rate = gs.best_params_['ADA__learning_rate']\n",
    "            feature_str = f'(n_estimators={n_est})(learning_rate={learn_rate})'\n",
    "        case _:\n",
    "            raise ValueError('The \\'model_name\\' parameter cannot be unspecified. Please set \\'model_name\\' equal to \\'kNN\\', \\'DT\\', \\'SVM-C\\', \\'RF-C\\', or \\'AdaBoost\\'.')\n",
    "        \n",
    "    return model, model_name+feature_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a9b2246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a grid search model on a pipeline and a parameter grid, printing the best results and returning the grid search.\n",
    "def get_grid_search_results(pipe, param_grid, x_train=X_train, x_test=X_test, y_train=Y_train, y_test=Y_test, n_jobs=N_JOBS, cv=CV, r_t_s=True, verbose=3, save_to_pkl=True):\n",
    "    grid_search = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=verbose,\n",
    "        return_train_score=r_t_s\n",
    "    )\n",
    "\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    if save_to_pkl:\n",
    "        steps = list(pipe.named_steps.keys())\n",
    "        m_name = steps[1] if steps[0] == 'scaler' else steps[0]\n",
    "        m, ftr_str = get_model_and_model_str(grid_search, m_name)\n",
    "        save_model(m, m_name, ftr_str)\n",
    "\n",
    "    print(f'Best Model: {grid_search.best_estimator_}')\n",
    "    print(f'Best Parameters: {grid_search.best_params_}')\n",
    "    print(f'Test Score: {grid_search.score(x_test, y_test)}')\n",
    "    print(f\"Mean Fit Time: {np.mean(grid_search.cv_results_['mean_fit_time'])}s\") #TODO: look into creating a way to track every single fit time? this one sucks\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95387602",
   "metadata": {},
   "source": [
    "### Analysis Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a76a2a",
   "metadata": {},
   "source": [
    "#### General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a93ac6",
   "metadata": {},
   "source": [
    "For supervised models, we can create a plot of feature importances and a confusion matrix for each model. This way we can determine, on average, which features are the most important across the board and how well each model is determining class assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1e2736c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a plot of feature importance using code adapted from the module 3 worksheet.\n",
    "def plot_feature_importances_from_supervised_grid_search(gs, model_name=None, x_tr=X_train, x_te=X_test, y_tr=Y_train, y_te=Y_test, save=True, n_repeats=10):\n",
    "    if model_name is None: raise ValueError('The \\'model_name\\' parameter cannot be unspecified. Please set \\'model_name\\' equal to \\'kNN\\', \\'DT\\', \\'SVM-C\\', \\'RF-C\\', or \\'AdaBoost\\'.')\n",
    "    # Gather information about the model\n",
    "    model, feature_str = get_model_and_model_str(gs, model_name=model_name)\n",
    "\n",
    "    # Get actual feature importances\n",
    "    model.fit(x_tr, y_tr)\n",
    "    r = permutation_importance(model, x_te, y_te, n_repeats=n_repeats, random_state=0)\n",
    "\n",
    "    n_features = len(FEATURES)\n",
    "    plt.barh(np.arange(n_features), r.importances_mean, align='center')\n",
    "    plt.yticks(np.arange(n_features), FEATURES)\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "    # Add a title and save the plot\n",
    "    plt.title(f'{model_name} SDSS Feature Importances {feature_str}')\n",
    "    plt.tight_layout()\n",
    "    if save: plt.savefig(paths['supervised_products'] + paths['charts'] + f'Feature_Importances_{feature_str}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31cfa348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a confusion matrix using the supervised grid_search's best estimator. Adapted from module 2 worksheet.\n",
    "def confusion_matrix_from_grid_search(gs, model_name=None, x_te=X_test, y_te=Y_test, save=True):\n",
    "    if model_name is None: raise ValueError('The \\'model_name\\' parameter cannot be unspecified. Please set \\'model_name\\' equal to \\'kNN\\', \\'DT\\', \\'SVM-C\\', \\'RF-C\\', or \\'AdaBoost\\'.')\n",
    "    \n",
    "    # Get information about the model\n",
    "    model, feature_str = get_model_and_model_str(gs, model_name=model_name)\n",
    "\n",
    "    cm = confusion_matrix(model.predict(x_te), y_te)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLASSES)\n",
    "    disp.plot(cmap='Blues')\n",
    "    disp.ax_.set_title(f'Confusion Matrix for {model_name}{feature_str}')\n",
    "    disp.figure_.tight_layout()\n",
    "    if save: disp.figure_.savefig(paths['supervised_products'] + paths['charts'] + f'Confusion_Matrix_{feature_str}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64247aaa",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9bbd30",
   "metadata": {},
   "source": [
    "For kNN models, we can create a plot of mean squared error against each attempted value for `n_neighbors` to visually understand why the best model was chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "058afc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the test score as a function of n_neighbors. Adapted from module 4 worksheet.\n",
    "def plot_test_score_vs_k_knn(gs_knn, save=True):\n",
    "    model, feature_str = get_model_and_model_str(gs_knn, model_name='kNN')\n",
    "    results = gs_knn.cv_results_['mean_test_score']\n",
    "    n_neighbors = len(gs_knn.cv_results_['mean_test_score'])\n",
    "    plt.scatter(np.arange(n_neighbors)+1, -results)\n",
    "    plt.xlabel('n_neighbors')\n",
    "    plt.ylabel('Test Score')\n",
    "    plt.title(f'kNN Test Score as n_neighbors approaches {n_neighbors}')\n",
    "    plt.xticks(np.arange(len(results)) + 1)\n",
    "    plt.tight_layout()\n",
    "    if save: plt.savefig(paths['supervised_products'] + paths['graphs'] + f'Test_Score_vs_k_{feature_str}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f97fc1",
   "metadata": {},
   "source": [
    "#### DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771e88e",
   "metadata": {},
   "source": [
    "For decision trees, we can optionally create a visual of the tree itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53b4352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a visual tree of the best estimator\n",
    "# TODO: may not be useful LOL\n",
    "def plot_grid_search_DT(gs_dt):\n",
    "    plot_tree(gs_dt.best_estimator_[0], feature_names=FEATURES, class_names=CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cabed1c",
   "metadata": {},
   "source": [
    "#### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c371ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: examine homework 3 question 1.a and 1.b, determine how to reproduce this graph, ideally for both supervised and unsupervised algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45d67a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a heatmap for an SVM classifier relating C-values to gamma-values.\n",
    "def svmc_heatmap(gs_svm, save=True):\n",
    "    # Get the details for the model and the best estimator's results\n",
    "    model, feature_str = get_model_and_model_str(gs_svm, model_name='SVM-C')\n",
    "    results = pd.DataFrame(gs_svm.cv_results_)\n",
    "\n",
    "    # Create the grid of C vs gamma\n",
    "    len_c = len(gs_svm.param_grid['SVM__C'])\n",
    "    len_gamma = len(gs_svm.param_grid['SVM__gamma'])\n",
    "    scores = np.array(results.mean_test_score).reshape(len_c, len_gamma).T\n",
    "\n",
    "    # Create the actual heatmap, labeled properly with scores included\n",
    "    ax = sns.heatmap(scores, annot=True, fmt=\".2f\",\n",
    "                     xticklabels=np.array(gs_svm.param_grid['SVM__C']).astype(str),\n",
    "                     yticklabels=np.array(gs_svm.param_grid['SVM__gamma']).astype(str))\n",
    "    ax.set_xlabel('C')\n",
    "    ax.set_ylabel('gamma')\n",
    "    ax.set_title(f\"Heatmap for {feature_str}\")\n",
    "    if save: ax.figure.savefig(paths['supervised_products'] + paths['charts'] + f'Heatmap_{feature_str}.png')\n",
    "    ax.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526dc5c",
   "metadata": {},
   "source": [
    "#### RF Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4836963",
   "metadata": {},
   "source": [
    "There are no model-specific analysis products for the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42405fb",
   "metadata": {},
   "source": [
    "#### AdaBoost Classifier with Base DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac786bcf",
   "metadata": {},
   "source": [
    "There are no model-specific analysis products for the AdaBoost Classifier with Base DT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ff351",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84478e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn, pg_knn = create_knn_for_grid_search()\n",
    "gs_knn = get_grid_search_results(pipe_knn, pg_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dt, pg_dt = create_dt_for_grid_search()\n",
    "gs_dt = get_grid_search_results(pipe_dt, pg_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svmc, pg_svmc = create_svmc_for_grid_search()\n",
    "gs_svmc = get_grid_search_results(pipe_svmc, pg_svmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68b374",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rfc, pg_rfc = create_rfc_for_grid_search()\n",
    "gs_rfc = get_grid_search_results(pipe_rfc, pg_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273cf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_adaboost, pg_adaboost = create_adaboost_for_grid_search()\n",
    "gs_adaboost = get_grid_search_results(pipe_adaboost, pg_adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c79d805",
   "metadata": {},
   "source": [
    "### Creating Analysis Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c6cdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Unsupervised Machine Learning\n",
    "\n",
    "This section contains training, optimization, testing, and creation of products for the following unsupervised machine learning algorithms:\n",
    "\n",
    "- k-Means Clustering (k-means)\n",
    "- Gaussian Mixture Model (GMM) Clustering\n",
    "- Density-Based Spatial Clustering of Applications with Noise (DBSCAN), using kNN for epsilon determination\n",
    "- Neural Network (NN) with [XXXX] layers of [XXXX] nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f06832",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "269f5edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for kMeans\n",
    "def create_kmeans_for_grid_search(n_clusters=len(CLASSES), n_init=10):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', SCALER), # k-Means requires feature scaling!\n",
    "        ('k-means', KMeans(random_state=0))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'k-means__n_clusters': n_clusters,\n",
    "        'k-means__n_init': n_init\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebac5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for GMM\n",
    "def create_gmm_for_grid_search(n_components=len(CLASSES), n_init=10):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', SCALER), # GMM requires feature scaling!\n",
    "        ('GMM', GaussianMixture(random_state=0))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'GMM__n_components': n_components,\n",
    "        'GMM__n_init': n_init\n",
    "    }\n",
    "    \n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe441e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for DBSCAN\n",
    "# TODO: include a k-nearest neighbors process in here for epsilon?\n",
    "def create_dbscan_for_grid_search(eps=np.arange(0, 1, 0.1), min_samples=np.arange(5, 16)):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', SCALER), # DBSCAN requires feature scaling!\n",
    "        ('DBSCAN', DBSCAN())\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'DBSCAN__eps': eps,\n",
    "        'DBSCAN__min_samples': min_samples\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6913bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: setup for NN - include two or three activation functions, a few batch sizes maybe, maybe different gradient descents?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e57063",
   "metadata": {},
   "source": [
    "### Analysis Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a9a35",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
