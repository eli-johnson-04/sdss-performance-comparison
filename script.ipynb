{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41272c33",
   "metadata": {},
   "source": [
    "# SDSS Performance Comparison | Hollis McLeod, Elijah Johnson\n",
    "\n",
    "The following code is the product of the combined efforts of Hollis McLeod and Elijah Johnson for the term project in the Fall 2025 Section #22904 of AST4930 - Special Topics: Machine Learning at the University of Florida. This code is not for viewing, use, analysis, or any other purposes not in compliance with the [University of Florida Honor Code](https://policy.ufl.edu/regulation/4-040/). Violations will be reported accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ee3aa",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4f37c",
   "metadata": {},
   "source": [
    "This Jupyter notebook defines a method for reading, processing, training machine learning models on, and visualizing results for [SDSS data](https://skyserver.sdss.org/dr19/SearchTools/sql) of the following form.\n",
    "\n",
    "500,000 rows were downloaded as *SDSS.csv*, although 100,000 rows are planned for use. If computational power permits, however, more will be used for increased rigor of analysis.\n",
    "\n",
    "**Fields**:\n",
    "- Identification and standard features of astronomical objects (not used for training)\n",
    "  - `objid`\n",
    "  - `ra`\n",
    "  - `dec`\n",
    "  - `specobjid`\n",
    "- Magnitudes\n",
    "  - `u`\n",
    "  - `g`\n",
    "  - `r`\n",
    "  - `i`\n",
    "  - `z`\n",
    "- Color indices (calculated)\n",
    "  - `u-g`\n",
    "  - `g-r`\n",
    "  - `r-i`\n",
    "  - `i-z`\n",
    "- `redshift`\n",
    "- `class`\n",
    "  - \"GALAXY\"\n",
    "  - \"QSO\" (shorthand for quasar)\n",
    "  - \"STAR\"\n",
    "\n",
    "**SQL Code**:\n",
    "```\n",
    "SELECT TOP 500000\n",
    "p.objid,p.ra,p.dec,p.u,p.g,p.r,p.i,p.z,\n",
    "p.u-p.g as 'u-g', p.g-p.r as 'g-r', p.r-p.i as 'r-i', p.i-p.z as 'i-z',\n",
    "s.specobjid, s.class, s.z as redshift\n",
    "FROM PhotoObj AS p\n",
    "JOIN SpecObj AS s ON s.bestobjid = p.objid\n",
    "WHERE s.class IN ('GALAXY', 'QSO', 'STAR')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed0472",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f815e896",
   "metadata": {},
   "source": [
    "### Install and Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360809dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Install if not already installed.\n",
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install scipy\n",
    "# %pip install matplotlib\n",
    "# %pip install scikit-learn\n",
    "# %pip install seaborn\n",
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b91dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Consolidate all imports together for easy use.\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# For capturing subprocess output with GridSearchCV parallelization\n",
    "from joblib import parallel_backend # TODO: currently unused!\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828cf7d5",
   "metadata": {},
   "source": [
    "### Define Paths and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c4be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These paths are stored in a dictionary for easy access and non-verbosity\n",
    "paths = {\n",
    "    # location of SDSS data\n",
    "    'data': './data/SDSS.csv',\n",
    "\n",
    "    # base directories for saved graphs, charts, models\n",
    "    'supervised_products': './products/supervised/',\n",
    "    'unsupervised_products': './products/unsupervised/',\n",
    "\n",
    "    # additional pathing for specific products\n",
    "    'graphs': 'graphs/',\n",
    "    'charts': 'charts/',\n",
    "    'models': 'models/',\n",
    "    'grid-searches': 'grid-searches/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787143ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The number of rows to be used with the data\n",
    "NROWS = 100000\n",
    "\n",
    "# The column names of the features and the class from the dataset\n",
    "FEATURES = ['u', 'g', 'r', 'i', 'z', 'u-g', 'g-r', 'r-i', 'i-z', 'redshift']\n",
    "CLASS = 'class'\n",
    "\n",
    "# The number of CPU cores we want to use for training, when possible. -1 means all that are available.\n",
    "N_JOBS = -1\n",
    "\n",
    "# Lists containing the names of the models in use.\n",
    "SUPERVISED_MODELS = ['kNN', 'DT', 'SVM-C', 'RF-C', 'AdaBoost']\n",
    "UNSUPERVISED_MODELS = ['k-means', 'GMM', 'DBSCAN', 'NN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d7482",
   "metadata": {},
   "source": [
    "### Import Data and Perform Preliminary Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02967757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(paths['data'], nrows=NROWS)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d69e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate into X and Y\n",
    "X = data[FEATURES].values\n",
    "Y = data[CLASS]\n",
    "\n",
    "CLASSES = np.unique(Y)\n",
    "\n",
    "print(f'SHAPES:\\n  -{X.shape}\\n  -{Y.shape}')\n",
    "print(f'CLASSES: {CLASSES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0475d821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef636e18",
   "metadata": {},
   "source": [
    "### Define Methods for Saving and Loading Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd6ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to extract the parameters of a model into a meaningful string for titles and filenames.\n",
    "def get_model_and_model_str(gs, model_name=None):\n",
    "    feature_str = ''\n",
    "    model = None\n",
    "    match model_name:\n",
    "        case 'kNN':\n",
    "            model = gs.best_estimator_[1]\n",
    "            n_neighbors = gs.best_params_['kNN__n_neighbors']\n",
    "            algo = gs.best_params_['kNN__algorithm']\n",
    "            feature_str = f'(k={n_neighbors})(algorithm={algo})'\n",
    "        case 'DT':\n",
    "            model = gs.best_estimator_[0]\n",
    "            m_d = gs.best_params_['DT__max_depth']\n",
    "            crit = gs.best_params_['DT__criterion']\n",
    "            feature_str = f'(max_depth={m_d})(criterion={crit})'\n",
    "        case 'SVM-C':\n",
    "            model = gs.best_estimator_[1]\n",
    "            c = gs.best_params_['SVM-C__C']\n",
    "            gamma = gs.best_params_['SVM-C__gamma']\n",
    "            feature_str = f'(C={c})(gamma={gamma})'\n",
    "        case 'RF-C':\n",
    "            model = gs.best_estimator_[0]\n",
    "            n_est = gs.best_params_['RF-C__n_estimators']\n",
    "            feature_str = f'(n_estimators={n_est})'\n",
    "        case 'AdaBoost':\n",
    "            model = gs.best_estimator_[0]\n",
    "            n_est = gs.best_params_['ADA__n_estimators']\n",
    "            learn_rate = gs.best_params_['ADA__learning_rate']\n",
    "            feature_str = f'(n_estimators={n_est})(learning_rate={learn_rate})'\n",
    "        case _:\n",
    "            raise ValueError('The \\'model_name\\' parameter cannot be unspecified. Please set \\'model_name\\' equal to \\'kNN\\', \\'DT\\', \\'SVM-C\\', \\'RF-C\\', or \\'AdaBoost\\'.')\n",
    "        \n",
    "    return model, model_name+feature_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1e51e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine the location for where a specific model is stored.\n",
    "def getloc_for_pkl(model_name, isModel=True):\n",
    "    loc = paths['supervised_products'] if model_name in SUPERVISED_MODELS \\\n",
    "                else paths['unsupervised_products'] if model_name in UNSUPERVISED_MODELS \\\n",
    "                else False\n",
    "    if not loc: raise ValueError('The \\'model_name\\' parameter must be equal to one of the models in use. Please see SUPERVISED_MODELS and UNSUPERVISED_MODELS.')\n",
    "    loc += paths['models'] if isModel else paths['grid-searches']\n",
    "    return loc\n",
    "\n",
    "# Save the model to a specific location with its features in its name.\n",
    "def save_model(model, model_name, feature_str):\n",
    "    loc = getloc_for_pkl(model_name)\n",
    "    with open(f'{loc}{feature_str}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "# Get the feature string of a filename.\n",
    "def get_feature_str_from_filename(f):\n",
    "    title = f.title()\n",
    "    last_backslash_index = title.rfind('\\\\')\n",
    "    filename = title[last_backslash_index + 1:]\n",
    "    last_period_index = filename.rfind('.')\n",
    "    feature_str = filename[:last_period_index]\n",
    "    return feature_str\n",
    "\n",
    "# Get a model from a specific location or by name. If by name, return the first result.\n",
    "def load_model(pkl_name=None, model_name=None, return_feature_str=False):\n",
    "    if model_name: loc = getloc_for_pkl(model_name)\n",
    "\n",
    "    # Get the name of the .pkl file based on which parameter was provided.\n",
    "    filename = glob.glob(f'{loc}{model_name}*.pkl' if model_name else pkl_name)[0]\n",
    "\n",
    "    with open(filename, 'rb') as f: \n",
    "        return pickle.load(f) if not return_feature_str else pickle.load(f), get_feature_str_from_filename(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save an entire grid search to a specific location\n",
    "def save_grid_search(gs, model_name):\n",
    "    model, feature_str = get_model_and_model_str(gs, model_name)\n",
    "    loc = getloc_for_pkl(model_name, isModel=False)\n",
    "    with open(f'{loc}{feature_str}.pkl', 'wb') as f:\n",
    "        pickle.dump(gs, f)\n",
    "\n",
    "# Get a grid search from a specific location or by name. If by name, return the first result.\n",
    "def load_grid_search(pkl_name=None, model_name=None, return_feature_str=False):\n",
    "    if model_name: loc = getloc_for_pkl(model_name, isModel=False)\n",
    "    \n",
    "    # Get the name of the .pkl file based on which parameter was provided\n",
    "    filename = glob.glob(f'{loc}{model_name}*.pkl' if model_name else pkl_name)[0]\n",
    "\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f) if not return_feature_str else pickle.load(f), get_feature_str_from_filename(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e06160",
   "metadata": {},
   "source": [
    "## Supervised Machine Learning\n",
    "\n",
    "This section contains training, optimization, testing, and creation of products for the following supervised machine learning algorithms:\n",
    "\n",
    "- k-Nearest Neighbors (kNN)\n",
    "- Decision Tree (DT)\n",
    "- Support Vector Machine Classifier (SVM-C)\n",
    "- Random Forest Classifier (RF-C)\n",
    "- Adaptive Boosting (AdaBoost) with Base DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac6aa8",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b8071",
   "metadata": {},
   "source": [
    "Define parameter grids for each model for `cv=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da15d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CV = 5\n",
    "SCALER = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768626a2",
   "metadata": {},
   "source": [
    "Define functions to create `Pipeline`s for each model, for experimentation and cleanliness. The default values for the hyperparameters may be tweaked and changed, since it is not necessary to risk overcompensating and wasting time for being unsure about what is needed. There will be sufficient evidence provided that the results of these parameters are indeed useful and meaningful, but the code required to determine sufficient ranges of hyperparameters and their respective outputs may not be included in the submission of this notebook.\n",
    "\n",
    "Models requiring feature scaling include a scaler in their pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5bd6e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for kNN\n",
    "def create_knn_for_grid_search(n_neighbors=np.arange(10)+1, algos=['auto']):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', SCALER), # kNN requires feature scaling!\n",
    "        ('kNN', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'kNN__n_neighbors': n_neighbors,\n",
    "        'kNN__algorithm': algos\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd598eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for DT\n",
    "def create_dt_for_grid_search(max_depth=np.arange(10)+1, criterion=['gini', 'entropy']):\n",
    "    pipe = Pipeline([\n",
    "        ('DT', DecisionTreeClassifier(random_state=0))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'DT__max_depth': max_depth,\n",
    "        'DT__criterion': criterion\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592b428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for SVM-C\n",
    "def create_svmc_for_grid_search(C=np.logspace(3, 6, num=4), gamma=np.logspace(-5, 0, num=4)):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', SCALER), # SVM requires feature scaling!\n",
    "        ('SVM-C', SVC(kernel='rbf', random_state=0))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'SVM-C__C': C,\n",
    "        'SVM-C__gamma': gamma\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32548e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for RF-C\n",
    "def create_rfc_for_grid_search(n_estimators=[100, 500, 1000, 5000]):\n",
    "    pipe = Pipeline([\n",
    "        ('RF-C', RandomForestClassifier(oob_score=True, random_state=0))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'RF-C__n_estimators': n_estimators\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23347f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for AdaBoost with Base DT.\n",
    "def create_adaboost_for_grid_search(n_estimators=[10, 50, 100, 200], learning_rate=[0.001, 0.01, 0.1, 1.0], max_depth=1, criterion='gini'):\n",
    "    # Per Worksheet 5, we want a poor base estimator for AdaBoost, so we default to max_depth=1 and criterion='gini.\n",
    "    pipe = Pipeline([\n",
    "        ('ADA', AdaBoostClassifier(\n",
    "            random_state=0,\n",
    "            estimator=DecisionTreeClassifier(\n",
    "                max_depth=max_depth,\n",
    "                criterion=criterion)))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'ADA__n_estimators': n_estimators,\n",
    "        'ADA__learning_rate': learning_rate\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffc0a3",
   "metadata": {},
   "source": [
    "Define a function to train models using a grid search with `CV` folds and `N_JOBS` cpu cores (defined above). This model takes the outputs of the functions above that produce pipelines and parameter grids for each type of supervised algorithm. This way, creating and training a model can be accomplished in just two lines! Given the volume of training and trial and error that will (likely) be needed, streamlining this process is essential for reducing headache. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b2246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a grid search model on a pipeline and a parameter grid, printing the best results and returning the grid search.\n",
    "def get_grid_search_results(pipe, param_grid, x_train=X_train, x_test=X_test, y_train=Y_train, y_test=Y_test, n_jobs=N_JOBS, cv=CV, r_t_s=True, verbose=3, save_model_to_pkl=True, save_gs_to_pkl=True):\n",
    "    grid_search = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=verbose,\n",
    "        return_train_score=r_t_s\n",
    "    )\n",
    "\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    if save_model_to_pkl:\n",
    "        steps = list(pipe.named_steps.keys())\n",
    "        m_name = steps[1] if steps[0] == 'scaler' else steps[0]\n",
    "        m, ftr_str = get_model_and_model_str(grid_search, m_name)\n",
    "        save_model(m, m_name, ftr_str)\n",
    "\n",
    "    if save_gs_to_pkl:\n",
    "        steps = list(pipe.named_steps.keys())\n",
    "        m_name = steps[1] if steps[0] == 'scaler' else steps[0]\n",
    "        save_grid_search(grid_search, m_name)\n",
    "\n",
    "    print(f'Best Model: {grid_search.best_estimator_}')\n",
    "    print(f'Best Parameters: {grid_search.best_params_}')\n",
    "    print(f'Test Score: {grid_search.score(x_test, y_test)}')\n",
    "    print(f\"Mean Fit Time: {np.mean(grid_search.cv_results_['mean_fit_time'])}s\") #TODO: look into creating a way to track every single fit time? this one sucks\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95387602",
   "metadata": {},
   "source": [
    "### Analysis Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a76a2a",
   "metadata": {},
   "source": [
    "#### General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a93ac6",
   "metadata": {},
   "source": [
    "For supervised models, we can create a plot of feature importances and a confusion matrix for each model. This way we can determine, on average, which features are the most important across the board and how well each model is determining class assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2736c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a plot of feature importance using code adapted from the module 3 worksheet.\n",
    "def plot_feature_importances_from_supervised_grid_search(gs, model_name=None, x_tr=X_train, x_te=X_test, y_tr=Y_train, y_te=Y_test, save=True, n_repeats=10):\n",
    "    if model_name is None: raise ValueError('The \\'model_name\\' parameter cannot be unspecified. Please set \\'model_name\\' equal to \\'kNN\\', \\'DT\\', \\'SVM-C\\', \\'RF-C\\', or \\'AdaBoost\\'.')\n",
    "    # Gather information about the model\n",
    "    model, feature_str = get_model_and_model_str(gs, model_name=model_name)\n",
    "\n",
    "    # Get actual feature importances\n",
    "    model.fit(x_tr, y_tr)\n",
    "    r = permutation_importance(model, x_te, y_te, n_repeats=n_repeats, random_state=0)\n",
    "\n",
    "    n_features = len(FEATURES)\n",
    "    plt.barh(np.arange(n_features), r.importances_mean, align='center')\n",
    "    plt.yticks(np.arange(n_features), FEATURES)\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "    # Add a title and save the plot\n",
    "    plt.title(f'{model_name} SDSS Feature Importances {feature_str}')\n",
    "    plt.tight_layout()\n",
    "    if save: plt.savefig(paths['supervised_products'] + paths['charts'] + f'Feature_Importances_{feature_str}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfa348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a confusion matrix using the supervised grid_search's best estimator. Adapted from module 2 worksheet.\n",
    "def confusion_matrix_from_grid_search(gs, model_name=None, x_te=X_test, y_te=Y_test, save=True):\n",
    "    if model_name is None: raise ValueError('The \\'model_name\\' parameter cannot be unspecified. Please set \\'model_name\\' equal to \\'kNN\\', \\'DT\\', \\'SVM-C\\', \\'RF-C\\', or \\'AdaBoost\\'.')\n",
    "    \n",
    "    # Get information about the model\n",
    "    model, feature_str = get_model_and_model_str(gs, model_name=model_name)\n",
    "\n",
    "    cm = confusion_matrix(model.predict(x_te), y_te)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLASSES)\n",
    "    disp.plot(cmap='Blues')\n",
    "    disp.ax_.set_title(f'Confusion Matrix for {model_name}{feature_str}')\n",
    "    disp.figure_.tight_layout()\n",
    "    if save: disp.figure_.savefig(paths['supervised_products'] + paths['charts'] + f'Confusion_Matrix_{feature_str}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64247aaa",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9bbd30",
   "metadata": {},
   "source": [
    "For kNN models, we can create a plot of mean squared error against each attempted value for `n_neighbors` to visually understand why the best model was chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058afc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the test score as a function of n_neighbors. Adapted from module 4 worksheet.\n",
    "def plot_test_score_vs_k_knn(gs_knn, save=True):\n",
    "    model, feature_str = get_model_and_model_str(gs_knn, model_name='kNN')\n",
    "    results = gs_knn.cv_results_['mean_test_score']\n",
    "    n_neighbors = len(gs_knn.cv_results_['mean_test_score'])\n",
    "    plt.scatter(np.arange(n_neighbors)+1, -results)\n",
    "    plt.xlabel('n_neighbors')\n",
    "    plt.ylabel('Test Score')\n",
    "    plt.title(f'kNN Test Score as n_neighbors approaches {n_neighbors}')\n",
    "    plt.xticks(np.arange(len(results)) + 1)\n",
    "    plt.tight_layout()\n",
    "    if save: plt.savefig(paths['supervised_products'] + paths['graphs'] + f'Test_Score_vs_k_{feature_str}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f97fc1",
   "metadata": {},
   "source": [
    "#### DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771e88e",
   "metadata": {},
   "source": [
    "For decision trees, we can optionally create a visual of the tree itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a visual tree of the best estimator\n",
    "# TODO: may not be useful LOL\n",
    "def plot_grid_search_DT(gs_dt):\n",
    "    plot_tree(gs_dt.best_estimator_[0], feature_names=FEATURES, class_names=CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cabed1c",
   "metadata": {},
   "source": [
    "#### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c371ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: examine homework 3 question 1.a and 1.b, determine how to reproduce this graph, ideally for both supervised and unsupervised algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d67a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a heatmap for an SVM classifier relating C-values to gamma-values.\n",
    "def svmc_heatmap(gs_svm, save=True):\n",
    "    # Get the details for the model and the best estimator's results\n",
    "    model, feature_str = get_model_and_model_str(gs_svm, model_name='SVM-C')\n",
    "    results = pd.DataFrame(gs_svm.cv_results_)\n",
    "\n",
    "    # Create the grid of C vs gamma\n",
    "    len_c = len(gs_svm.param_grid['SVM-C__C'])\n",
    "    len_gamma = len(gs_svm.param_grid['SVM-C__gamma'])\n",
    "    scores = np.array(results.mean_test_score).reshape(len_c, len_gamma).T\n",
    "\n",
    "    # Create the actual heatmap, labeled properly with scores included\n",
    "    ax = sns.heatmap(scores, annot=True, fmt=\".2f\",\n",
    "                     xticklabels=np.array(gs_svm.param_grid['SVM-C__C']).astype(str),\n",
    "                     yticklabels=np.array(gs_svm.param_grid['SVM-C__gamma']).astype(str))\n",
    "    ax.set_xlabel('C')\n",
    "    ax.set_ylabel('gamma')\n",
    "    ax.set_title(f\"Heatmap for {feature_str}\")\n",
    "    if save: ax.figure.savefig(paths['supervised_products'] + paths['charts'] + f'Heatmap_{feature_str}.png')\n",
    "    ax.figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526dc5c",
   "metadata": {},
   "source": [
    "#### RF Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4836963",
   "metadata": {},
   "source": [
    "There are no model-specific analysis products for the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42405fb",
   "metadata": {},
   "source": [
    "#### AdaBoost Classifier with Base DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac786bcf",
   "metadata": {},
   "source": [
    "There are no model-specific analysis products for the AdaBoost Classifier with Base DT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ff351",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84478e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn, pg_knn = create_knn_for_grid_search()\n",
    "gs_knn = get_grid_search_results(pipe_knn, pg_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dt, pg_dt = create_dt_for_grid_search()\n",
    "gs_dt = get_grid_search_results(pipe_dt, pg_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svmc, pg_svmc = create_svmc_for_grid_search()\n",
    "gs_svmc = get_grid_search_results(pipe_svmc, pg_svmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68b374",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rfc, pg_rfc = create_rfc_for_grid_search()\n",
    "gs_rfc = get_grid_search_results(pipe_rfc, pg_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273cf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_adaboost, pg_adaboost = create_adaboost_for_grid_search()\n",
    "gs_adaboost = get_grid_search_results(pipe_adaboost, pg_adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c79d805",
   "metadata": {},
   "source": [
    "### Creating Analysis Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c6cdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Unsupervised Machine Learning\n",
    "\n",
    "This section contains training, optimization, testing, and creation of products for the following unsupervised machine learning algorithms:\n",
    "\n",
    "- k-Means Clustering (k-means)\n",
    "- Gaussian Mixture Model (GMM) Clustering\n",
    "- Density-Based Spatial Clustering of Applications with Noise (DBSCAN), using kNN for epsilon determination\n",
    "- Neural Network (NN) with [XXXX] layers of [XXXX] nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f06832",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f5edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for kMeans\n",
    "def create_kmeans_for_grid_search(n_clusters=len(CLASSES), n_init=10):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', SCALER), # k-Means requires feature scaling!\n",
    "        ('k-means', KMeans(random_state=0))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'k-means__n_clusters': n_clusters,\n",
    "        'k-means__n_init': n_init\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for GMM\n",
    "def create_gmm_for_grid_search(n_components=len(CLASSES), n_init=10):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', SCALER), # GMM requires feature scaling!\n",
    "        ('GMM', GaussianMixture(random_state=0))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'GMM__n_components': n_components,\n",
    "        'GMM__n_init': n_init\n",
    "    }\n",
    "    \n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe441e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a pipeline and parameter grid for DBSCAN\n",
    "# TODO: include a k-nearest neighbors process in here for epsilon?\n",
    "def create_dbscan_for_grid_search(eps=np.arange(0, 1, 0.1), min_samples=np.arange(5, 16)):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', SCALER), # DBSCAN requires feature scaling!\n",
    "        ('DBSCAN', DBSCAN())\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'DBSCAN__eps': eps,\n",
    "        'DBSCAN__min_samples': min_samples\n",
    "    }\n",
    "\n",
    "    return pipe, param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6913bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: setup for NN - include two or three activation functions, a few batch sizes maybe, maybe different gradient descents?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e57063",
   "metadata": {},
   "source": [
    "### Analysis Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a9a35",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
